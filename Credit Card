if("pacman" %in% rownames(installed.packages()) == FALSE) {install.packages("pacman")}
pacman::p_load("caret","ROCR","lift","glmnet","MASS","e1071", "pracma")

##
## Function Definitions
##

fixNAs<-function(data_frame){
  integer_reac<-0
  factor_reac<-"FIXED_NA"
  character_reac<-"FIXED_NA"
  date_reac<-as.Date("1900-01-01")
  
  for (i in 1 : ncol(data_frame)){
    if (class(data_frame[,i]) %in% c("numeric","integer")) {
      if (any(is.na(data_frame[,i]))){
        data_frame[,paste0(colnames(data_frame)[i],"_surrogate")]<-
          as.factor(ifelse(is.na(data_frame[,i]),"1","0"))
        data_frame[is.na(data_frame[,i]),i]<-integer_reac
      }
    } else
      if (class(data_frame[,i]) %in% c("factor")) {
        if (any(is.na(data_frame[,i]))){
          data_frame[,i]<-as.character(data_frame[,i])
          data_frame[,paste0(colnames(data_frame)[i],"_surrogate")]<-
            as.factor(ifelse(is.na(data_frame[,i]),"1","0"))
          data_frame[is.na(data_frame[,i]),i]<-factor_reac
          data_frame[,i]<-as.factor(data_frame[,i])
          
        } 
      } else {
        if (class(data_frame[,i]) %in% c("character")) {
          if (any(is.na(data_frame[,i]))){
            data_frame[,paste0(colnames(data_frame)[i],"_surrogate")]<-
              as.factor(ifelse(is.na(data_frame[,i]),"1","0"))
            data_frame[is.na(data_frame[,i]),i]<-character_reac
          }  
        } else {
          if (class(data_frame[,i]) %in% c("Date")) {
            if (any(is.na(data_frame[,i]))){
              data_frame[,paste0(colnames(data_frame)[i],"_surrogate")]<-
                as.factor(ifelse(is.na(data_frame[,i]),"1","0"))
              data_frame[is.na(data_frame[,i]),i]<-date_reac
            }
          }  
        }       
      }
  } 
  return(data_frame) 
}

combineRareCategories<-function(data_frame,mincount){ 
  for (i in 1 : ncol(data_frame)){
    a<-data_frame[,i]
    replace <- names(which(table(a) < mincount))
    levels(a)[levels(a) %in% replace] <-paste("Other",colnames(data_frame)[i],sep=".")
    data_frame[,i]<-a }
  return(data_frame) 
}

##
## Fixing bad data
##

CreditCard <- read.csv(file.choose(), na.strings=c(""," ","NA"), header=TRUE) # Loading data

CreditCard$SEX <- as.factor(CreditCard$SEX)

# EDUCATION (0 and 6 values are corrected to 5, unknown)
CreditCard$EDUCATION[CreditCard$EDUCATION <= 0] <- 5
CreditCard$EDUCATION[CreditCard$EDUCATION >= 6] <- 5
CreditCard$EDUCATION <- as.factor(CreditCard$EDUCATION)

# MARRIAGE (0 values are corrected to 3, other)
CreditCard$MARRIAGE[CreditCard$MARRIAGE <= 0] <- 3
CreditCard$MARRIAGE[CreditCard$MARRIAGE >= 3] <- 3
CreditCard$MARRIAGE <- as.factor(CreditCard$MARRIAGE)

CreditCard$PAY_1 <- as.factor(CreditCard$PAY_1)
CreditCard$PAY_2 <- as.factor(CreditCard$PAY_2)
CreditCard$PAY_3 <- as.factor(CreditCard$PAY_3)
CreditCard$PAY_4 <- as.factor(CreditCard$PAY_4)
CreditCard$PAY_5 <- as.factor(CreditCard$PAY_5)
CreditCard$PAY_6 <- as.factor(CreditCard$PAY_6)
CreditCard$default_0 <- as.factor(CreditCard$default_0)
CreditCard$PAY_AMT1 <- as.numeric(CreditCard$PAY_AMT1)
CreditCard$PAY_AMT2 <- as.numeric(CreditCard$PAY_AMT2)
CreditCard$PAY_AMT3 <- as.numeric(CreditCard$PAY_AMT3)
CreditCard$PAY_AMT4 <- as.numeric(CreditCard$PAY_AMT4)
CreditCard$PAY_AMT5 <- as.numeric(CreditCard$PAY_AMT5)
CreditCard$PAY_AMT6 <- as.numeric(CreditCard$PAY_AMT6)

# Fixing NAs
CreditCard<-fixNAs(CreditCard)
# Grouping rare variables
CreditCard<-combineRareCategories(CreditCard, 20)

##
## Separating the data using the method in class
##

set.seed(77850) #set a random number generation seed to ensure that the split is the same everytime
inTrain <- createDataPartition(y = CreditCard$default_0,
                               p = 19200/24000, list = FALSE)
training <- CreditCard[ inTrain,]
testing <- CreditCard[ -inTrain,]

##
## Defining the model using logistic
##

# define model
# model_logistic<-glm(default_0 ~
#                       LIMIT_BAL + 
#                       SEX + 
#                       EDUCATION + 
#                       MARRIAGE +
#                       AGE +
#                       PAY_1 + 
#                       PAY_2 + 
#                       PAY_3 + 
#                       PAY_4 + 
#                       PAY_5 + 
#                       PAY_6 + 
#                       BILL_AMT1 +
#                       BILL_AMT2 +
#                       BILL_AMT3 +
#                       BILL_AMT4 +
#                       BILL_AMT5 +
#                       BILL_AMT6 +
#                       PAY_AMT1 + 
#                       PAY_AMT2 + 
#                       PAY_AMT3 +
#                       PAY_AMT4 +
#                       PAY_AMT5 +
#                       PAY_AMT6,
#                     data=training, family="binomial"(link="logit"))

model_logistic<-glm(default_0 ~ LIMIT_BAL + 
                      SEX + EDUCATION + MARRIAGE +
                      AGE + PAY_1 + PAY_2 + PAY_3 + PAY_4 +PAY_5 +PAY_6 +
                      BILL_AMT1 + BILL_AMT2 + BILL_AMT3 +BILL_AMT4 +BILL_AMT5 +BILL_AMT6 + 
                      PAY_AMT1 + PAY_AMT2 + PAY_AMT3+ PAY_AMT4+ PAY_AMT5+ PAY_AMT6 , family="binomial"(link="logit"))

# generate summary
summary(model_logistic) 

##
## Walking through the model stepwise, AIC
##

model_logistic_stepwiseAIC <- stepAIC(model_logistic, direction = c("both"),trace = 1)
summary(model_logistic_stepwiseAIC) 

par(mfrow=c(1,4))
plot(model_logistic_stepwiseAIC) #Error plots: similar nature to lm plots
par(mfrow=c(1,1))

##
## Prediction
##

model_chosen <- model_logistic
avg_probability <- mean(training$default_0 == "1")

# Step 1: Predict probabilities
logistic_probabilities<-predict(model_chosen, newdata=testing, type="response")

# Step 2: Create a row with all 1s
logistic_classification<-rep("1",nrow(testing))

#Step 3: used the code from class


logistic_probabilities<-predict(model_logistic_stepwiseAIC,newdata=testing,type="response") #Predict probabilities
logistic_classification<-rep("1",2400)
logistic_classification[logistic_probabilities<0.22]="0" #Predict classification using 0.6073 threshold. Why 0.6073 - that's the average probability of being retained in the data. An alternative code: logistic_classification <- as.integer(logistic_probabilities > mean(testing$Retained.in.2012. == "1"))
logistic_classification<-as.factor(logistic_classification)
##
## Final Analysis (Confusion Matrix, ROC Curve, AUC)
##

# Confusion matrix  
confusionMatrix(logistic_classification,testing$default_0,positive = "1") #Display confusion matrix

# ROC Curve
logistic_ROC_prediction <- prediction(logistic_probabilities, testing$default_0)
logistic_ROC <- performance(logistic_ROC_prediction,"tpr","fpr") # Create ROC curve data
plot(logistic_ROC) # Plot ROC curve

# AUC (area under curve)
# 90+% - excellent, 80-90% - very good, 70-80% - good, 60-70% - so so, below 60% - not much value
auc.tmp <- performance(logistic_ROC_prediction,"auc") #Create AUC data
logistic_auc_testing <- as.numeric(auc.tmp@y.values) #Calculate AUC
logistic_auc_testing

#### Lift chart
plotLift(logistic_probabilities, testing$default_0, cumulative = TRUE, n.buckets = 10)

###


# other models (model #2)
#CART using ctree

ctree_tree<-ctree(default_0~.,data=training) #Run ctree on training data
plot(ctree_tree, gp = gpar(fontsize = 8)) #Plotting the tree (adjust fontsize if needed)

ctree_probabilities<-predict(ctree_tree,newdata=testing,type="prob") #Predict probabilities
ctree_classification<-rep("1",2400)
ctree_classification[ctree_probabilities[,2]<0.22]="0" #Predict classification using 0.6073 threshold. Why 0.6073 - that's the average probability of being retained in the data. An alternative code: logistic_classification <- as.integer(logistic_probabilities > mean(testing$Retained.in.2012. == "1"))
ctree_classification<-as.factor(ctree_classification)

###Confusion matrix  
confusionMatrix(ctree_classification,testing$default_0,positive = "1")

####ROC Curve
ctree_probabilities_testing <-predict(ctree_tree,newdata=testing,type = "prob") #Predict probabilities
ctree_pred_testing <- prediction(ctree_probabilities_testing[,2], testing$default_0) #Calculate errors
ctree_ROC_testing <- performance(ctree_pred_testing,"tpr","fpr") #Create ROC curve data
plot(ctree_ROC_testing) #Plot ROC curve

####AUC (area under curve)
auc.tmp <- performance(ctree_pred_testing,"auc") #Create AUC data
ctree_auc_testing <- as.numeric(auc.tmp@y.values) #Calculate AUC
ctree_auc_testing #Display AUC value: 90+% - excellent, 80-90% - very good, 70-80% - good, 60-70% - so so, below 60% - not much value

#### Lift chart
plotLift(ctree_probabilities[,2],  testing$default_0, cumulative = TRUE, n.buckets = 10) # Plot Lift chart



# other models (model #3)

###
### RPART
###

# The rpart method has an important "complexity parameter", cp, which determines how big the tree is.  

CART_cp = rpart.control(cp = 0.0009) #set cp to a small number to "grow" a large tree

rpart_tree<-rpart(default_0~.,data=training, method="class", control=CART_cp) #"Grow" a tree on training data

prunned_rpart_tree<-prune(rpart_tree, cp=0.009) #Prun the tree. Play with cp to see how the resultant tree changes
plot(as.party(prunned_rpart_tree), type = "extended",gp = gpar(fontsize = 7)) #Plotting the tree (adjust fontsize if needed)

printcp(rpart_tree) # Understand the relationship between the cross-validated error, size of the tree and cp
plotcp(rpart_tree) # As a rule of thumb pick up the largest cp which does not give a substantial drop in error

rpart_prediction_class<-predict(prunned_rpart_tree,newdata=testing, type="class") #Predict classification (for confusion matrix)
confusionMatrix(rpart_prediction_class,testing$default_0,positive = "1") #Display confusion matrix

rpart_probabilities_testing <-predict(prunned_rpart_tree,newdata=testing,type = "prob") #Predict probabilities
rpart_pred_testing <- prediction(rpart_probabilities_testing[,2], testing$default_0) #Calculate errors
rpart_ROC_testing <- performance(rpart_pred_testing,"tpr","fpr") #Create ROC curve data
plot(rpart_ROC_testing) #Plot ROC curve

auc.tmp <- performance(rpart_pred_testing,"auc") #Create AUC data
rpart_auc_testing <- as.numeric(auc.tmp@y.values) #Calculate AUC
rpart_auc_testing #Display AUC value

plotLift(rpart_prediction_class,  testing$default_0, cumulative = TRUE, n.buckets = 10) # Plot Lift chart
